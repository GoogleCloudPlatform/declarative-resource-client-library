// Copyright 2021 Google LLC. All Rights Reserved.
// 
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
// 
//     http://www.apache.org/licenses/LICENSE-2.0
// 
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.
syntax = "proto3";

package dcl;

import "proto/connector/sdk.proto";
import "proto/empty.proto";
import "cloud/graphite/mmv2/services/google/dataproc/cluster.proto";

message DataprocWorkflowTemplate {
  string name = 1;
  int64 version = 2;
  string create_time = 3;
  string update_time = 4;
  map<string, string> labels = 5;
  DataprocWorkflowTemplatePlacement placement = 6;
  repeated DataprocWorkflowTemplateJobs jobs = 7;
  repeated DataprocWorkflowTemplateParameters parameters = 8;
  string project = 9;
  string location = 10;
}

message DataprocWorkflowTemplatePlacement {
  DataprocWorkflowTemplatePlacementManagedCluster managed_cluster = 1;
  DataprocWorkflowTemplatePlacementClusterSelector cluster_selector = 2;
}

message DataprocWorkflowTemplatePlacementManagedCluster {
  string cluster_name = 1;
  DataprocClusterClusterConfig config = 2;
  map<string, string> labels = 3;
}

message DataprocWorkflowTemplatePlacementClusterSelector {
  string zone = 1;
  map<string, string> cluster_labels = 2;
}

message DataprocWorkflowTemplateJobs {
  string step_id = 1;
  DataprocWorkflowTemplateJobsHadoopJob hadoop_job = 2;
  DataprocWorkflowTemplateJobsSparkJob spark_job = 3;
  DataprocWorkflowTemplateJobsPysparkJob pyspark_job = 4;
  DataprocWorkflowTemplateJobsHiveJob hive_job = 5;
  DataprocWorkflowTemplateJobsPigJob pig_job = 6;
  DataprocWorkflowTemplateJobsSparkRJob spark_r_job = 7;
  DataprocWorkflowTemplateJobsSparkSqlJob spark_sql_job = 8;
  DataprocWorkflowTemplateJobsPrestoJob presto_job = 9;
  map<string, string> labels = 10;
  DataprocWorkflowTemplateJobsScheduling scheduling = 11;
  repeated string prerequisite_step_ids = 12;
}

message DataprocWorkflowTemplateJobsHadoopJob {
  string main_jar_file_uri = 1;
  string main_class = 2;
  repeated string args = 3;
  repeated string jar_file_uris = 4;
  repeated string file_uris = 5;
  repeated string archive_uris = 6;
  map<string, string> properties = 7;
  DataprocWorkflowTemplateJobsHadoopJobLoggingConfig logging_config = 8;
}

message DataprocWorkflowTemplateJobsHadoopJobLoggingConfig {
  map<string, string> driver_log_levels = 1;
}

message DataprocWorkflowTemplateJobsSparkJob {
  string main_jar_file_uri = 1;
  string main_class = 2;
  repeated string args = 3;
  repeated string jar_file_uris = 4;
  repeated string file_uris = 5;
  repeated string archive_uris = 6;
  map<string, string> properties = 7;
  DataprocWorkflowTemplateJobsSparkJobLoggingConfig logging_config = 8;
}

message DataprocWorkflowTemplateJobsSparkJobLoggingConfig {
  map<string, string> driver_log_levels = 1;
}

message DataprocWorkflowTemplateJobsPysparkJob {
  string main_python_file_uri = 1;
  repeated string args = 2;
  repeated string python_file_uris = 3;
  repeated string jar_file_uris = 4;
  repeated string file_uris = 5;
  repeated string archive_uris = 6;
  map<string, string> properties = 7;
  DataprocWorkflowTemplateJobsPysparkJobLoggingConfig logging_config = 8;
}

message DataprocWorkflowTemplateJobsPysparkJobLoggingConfig {
  map<string, string> driver_log_levels = 1;
}

message DataprocWorkflowTemplateJobsHiveJob {
  string query_file_uri = 1;
  DataprocWorkflowTemplateJobsHiveJobQueryList query_list = 2;
  bool continue_on_failure = 3;
  map<string, string> script_variables = 4;
  map<string, string> properties = 5;
  repeated string jar_file_uris = 6;
}

message DataprocWorkflowTemplateJobsHiveJobQueryList {
  repeated string queries = 1;
}

message DataprocWorkflowTemplateJobsPigJob {
  string query_file_uri = 1;
  DataprocWorkflowTemplateJobsPigJobQueryList query_list = 2;
  bool continue_on_failure = 3;
  map<string, string> script_variables = 4;
  map<string, string> properties = 5;
  repeated string jar_file_uris = 6;
  DataprocWorkflowTemplateJobsPigJobLoggingConfig logging_config = 7;
}

message DataprocWorkflowTemplateJobsPigJobQueryList {
  repeated string queries = 1;
}

message DataprocWorkflowTemplateJobsPigJobLoggingConfig {
  map<string, string> driver_log_levels = 1;
}

message DataprocWorkflowTemplateJobsSparkRJob {
  string main_r_file_uri = 1;
  repeated string args = 2;
  repeated string file_uris = 3;
  repeated string archive_uris = 4;
  map<string, string> properties = 5;
  DataprocWorkflowTemplateJobsSparkRJobLoggingConfig logging_config = 6;
}

message DataprocWorkflowTemplateJobsSparkRJobLoggingConfig {
  map<string, string> driver_log_levels = 1;
}

message DataprocWorkflowTemplateJobsSparkSqlJob {
  string query_file_uri = 1;
  DataprocWorkflowTemplateJobsSparkSqlJobQueryList query_list = 2;
  map<string, string> script_variables = 3;
  map<string, string> properties = 4;
  repeated string jar_file_uris = 5;
  DataprocWorkflowTemplateJobsSparkSqlJobLoggingConfig logging_config = 6;
}

message DataprocWorkflowTemplateJobsSparkSqlJobQueryList {
  repeated string queries = 1;
}

message DataprocWorkflowTemplateJobsSparkSqlJobLoggingConfig {
  map<string, string> driver_log_levels = 1;
}

message DataprocWorkflowTemplateJobsPrestoJob {
  string query_file_uri = 1;
  DataprocWorkflowTemplateJobsPrestoJobQueryList query_list = 2;
  bool continue_on_failure = 3;
  string output_format = 4;
  repeated string client_tags = 5;
  map<string, string> properties = 6;
  DataprocWorkflowTemplateJobsPrestoJobLoggingConfig logging_config = 7;
}

message DataprocWorkflowTemplateJobsPrestoJobQueryList {
  repeated string queries = 1;
}

message DataprocWorkflowTemplateJobsPrestoJobLoggingConfig {
  map<string, string> driver_log_levels = 1;
}

message DataprocWorkflowTemplateJobsScheduling {
  int64 max_failures_per_hour = 1;
  int64 max_failures_total = 2;
}

message DataprocWorkflowTemplateParameters {
  string name = 1;
  repeated string fields = 2;
  string description = 3;
  DataprocWorkflowTemplateParametersValidation validation = 4;
}

message DataprocWorkflowTemplateParametersValidation {
  DataprocWorkflowTemplateParametersValidationRegex regex = 1;
  DataprocWorkflowTemplateParametersValidationValues values = 2;
}

message DataprocWorkflowTemplateParametersValidationRegex {
  repeated string regexes = 1;
}

message DataprocWorkflowTemplateParametersValidationValues {
  repeated string values = 1;
}

message ApplyDataprocWorkflowTemplateRequest {
  DataprocWorkflowTemplate resource = 1;
  repeated LifecycleDirective lifecycle_directives = 2;
  string service_account_file = 3;
}

message DeleteDataprocWorkflowTemplateRequest {
  string service_account_file = 1;
  DataprocWorkflowTemplate resource = 2;
}

message ListDataprocWorkflowTemplateRequest {
  string service_account_file = 1;
  string Project = 2;
  string Location = 3;
}

message ListDataprocWorkflowTemplateResponse {
  repeated DataprocWorkflowTemplate items = 1;
}
service DataprocWorkflowTemplateService {
  rpc ApplyDataprocWorkflowTemplate(ApplyDataprocWorkflowTemplateRequest) returns (DataprocWorkflowTemplate);
  rpc DeleteDataprocWorkflowTemplate(DeleteDataprocWorkflowTemplateRequest) returns (google.protobuf.Empty);
  rpc ListDataprocWorkflowTemplate(ListDataprocWorkflowTemplateRequest) returns (ListDataprocWorkflowTemplateResponse);
}
