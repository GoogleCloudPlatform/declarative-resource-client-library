# Copyright 2021 Google LLC. All Rights Reserved.
# 
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
# 
#     http://www.apache.org/licenses/LICENSE-2.0
# 
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
info:
  title: Dataproc/WorkflowTemplate
  description: DCL Specification for the Dataproc WorkflowTemplate resource
  x-dcl-has-iam: false
paths:
  get:
    description: The function used to get information about a WorkflowTemplate
    parameters:
    - name: WorkflowTemplate
      required: true
      description: A full instance of a WorkflowTemplate
  apply:
    description: The function used to apply information about a WorkflowTemplate
    parameters:
    - name: WorkflowTemplate
      required: true
      description: A full instance of a WorkflowTemplate
  delete:
    description: The function used to delete a WorkflowTemplate
    parameters:
    - name: WorkflowTemplate
      required: true
      description: A full instance of a WorkflowTemplate
  deleteAll:
    description: The function used to delete all WorkflowTemplate
    parameters:
    - name: project
      required: true
      schema:
        type: string
    - name: location
      required: true
      schema:
        type: string
  list:
    description: The function used to list information about many WorkflowTemplate
    parameters:
    - name: project
      required: true
      schema:
        type: string
    - name: location
      required: true
      schema:
        type: string
components:
  schemas:
    ClusterConfig:
      type: object
      x-dcl-go-name: Config
      x-dcl-go-type: ClusterClusterConfig
      description: Required. The cluster configuration.
      properties:
        autoscalingConfig:
          type: object
          x-dcl-go-name: AutoscalingConfig
          x-dcl-go-type: ClusterClusterConfigAutoscalingConfig
          description: Optional. Autoscaling config for the policy associated with
            the cluster. Cluster does not autoscale if this field is unset.
          properties:
            policy:
              type: string
              x-dcl-go-name: Policy
              description: 'Optional. The autoscaling policy used by the cluster.
                Only resource names including projectid and location (region) are
                valid. Examples: * `https://www.googleapis.com/compute/v1/projects/`
                Note that the policy must be in the same project and Dataproc region.'
              x-dcl-references:
              - resource: Dataproc/AutoscalingPolicy
                field: name
        encryptionConfig:
          type: object
          x-dcl-go-name: EncryptionConfig
          x-dcl-go-type: ClusterClusterConfigEncryptionConfig
          description: Optional. Encryption settings for the cluster.
          properties:
            gcePdKmsKeyName:
              type: string
              x-dcl-go-name: GcePdKmsKeyName
              description: Optional. The Cloud KMS key name to use for PD disk encryption
                for all instances in the cluster.
              x-dcl-references:
              - resource: Cloudkms/CryptoKey
                field: selfLink
        endpointConfig:
          type: object
          x-dcl-go-name: EndpointConfig
          x-dcl-go-type: ClusterClusterConfigEndpointConfig
          description: Optional. Port/endpoint configuration for this cluster
          properties:
            enableHttpPortAccess:
              type: boolean
              x-dcl-go-name: EnableHttpPortAccess
              description: Optional. If true, enable http access to specific ports
                on the cluster from external sources. Defaults to false.
            httpPorts:
              type: object
              additionalProperties:
                type: string
              x-dcl-go-name: HttpPorts
              readOnly: true
              description: Output only. The map of port descriptions to URLs. Will
                only be populated if enable_http_port_access is true.
        gceClusterConfig:
          type: object
          x-dcl-go-name: GceClusterConfig
          x-dcl-go-type: ClusterClusterConfigGceClusterConfig
          description: Optional. The shared Compute Engine config settings for all
            instances in a cluster.
          properties:
            internalIPOnly:
              type: boolean
              x-dcl-go-name: InternalIPOnly
              description: Optional. If true, all instances in the cluster will only
                have internal IP addresses. By default, clusters are not restricted
                to internal IP addresses, and will have ephemeral external IP addresses
                assigned to each instance. This `internal_ip_only` restriction can
                only be enabled for subnetwork enabled networks, and all off-cluster
                dependencies must be configured to be accessible without external
                IP addresses.
              x-dcl-server-default: true
            metadata:
              type: object
              additionalProperties:
                type: string
              x-dcl-go-name: Metadata
              description: The Compute Engine metadata entries to add to all instances
                (see (https://cloud.google.com/compute/docs/storing-retrieving-metadata#project_and_instance_metadata)).
            network:
              type: string
              x-dcl-go-name: Network
              description: Optional. The Compute Engine network to be used for machine
                communications. Cannot be specified with subnetwork_uri. If neither
                `network_uri` nor `subnetwork_uri` is specified, the "default" network
                of the project is used, if it exists. Cannot be a "Custom Subnet Network"
                (see /regions/global/default` * `default`
              x-dcl-references:
              - resource: Compute/Network
                field: selfLink
            nodeGroupAffinity:
              type: object
              x-dcl-go-name: NodeGroupAffinity
              x-dcl-go-type: ClusterClusterConfigGceClusterConfigNodeGroupAffinity
              description: Optional. Node Group Affinity for sole-tenant clusters.
              required:
              - nodeGroup
              properties:
                nodeGroup:
                  type: string
                  x-dcl-go-name: NodeGroup
                  description: Required. The URI of a sole-tenant /zones/us-central1-a/nodeGroups/node-group-1`
                    * `node-group-1`
                  x-dcl-references:
                  - resource: Compute/NodeGroup
                    field: selfLink
            privateIPv6GoogleAccess:
              type: string
              x-dcl-go-name: PrivateIPv6GoogleAccess
              x-dcl-go-type: ClusterClusterConfigGceClusterConfigPrivateIPv6GoogleAccessEnum
              description: 'Optional. The type of IPv6 access for a cluster. Possible
                values: PRIVATE_IPV6_GOOGLE_ACCESS_UNSPECIFIED, INHERIT_FROM_SUBNETWORK,
                OUTBOUND, BIDIRECTIONAL'
              enum:
              - PRIVATE_IPV6_GOOGLE_ACCESS_UNSPECIFIED
              - INHERIT_FROM_SUBNETWORK
              - OUTBOUND
              - BIDIRECTIONAL
            reservationAffinity:
              type: object
              x-dcl-go-name: ReservationAffinity
              x-dcl-go-type: ClusterClusterConfigGceClusterConfigReservationAffinity
              description: Optional. Reservation Affinity for consuming Zonal reservation.
              properties:
                consumeReservationType:
                  type: string
                  x-dcl-go-name: ConsumeReservationType
                  x-dcl-go-type: ClusterClusterConfigGceClusterConfigReservationAffinityConsumeReservationTypeEnum
                  description: 'Optional. Type of reservation to consume Possible
                    values: TYPE_UNSPECIFIED, NO_RESERVATION, ANY_RESERVATION, SPECIFIC_RESERVATION'
                  enum:
                  - TYPE_UNSPECIFIED
                  - NO_RESERVATION
                  - ANY_RESERVATION
                  - SPECIFIC_RESERVATION
                key:
                  type: string
                  x-dcl-go-name: Key
                  description: Optional. Corresponds to the label key of reservation
                    resource.
                values:
                  type: array
                  x-dcl-go-name: Values
                  description: Optional. Corresponds to the label values of reservation
                    resource.
                  x-dcl-list-type: list
                  items:
                    type: string
                    x-dcl-go-type: string
            serviceAccount:
              type: string
              x-dcl-go-name: ServiceAccount
              description: Optional. The (https://cloud.google.com/compute/docs/access/service-accounts#default_service_account)
                is used.
              x-dcl-references:
              - resource: Iam/ServiceAccount
                field: email
            serviceAccountScopes:
              type: array
              x-dcl-go-name: ServiceAccountScopes
              description: 'Optional. The URIs of service account scopes to be included
                in Compute Engine instances. The following base set of scopes is always
                included: * https://www.googleapis.com/auth/cloud.useraccounts.readonly
                * https://www.googleapis.com/auth/devstorage.read_write * https://www.googleapis.com/auth/logging.write
                If no scopes are specified, the following defaults are also provided:
                * https://www.googleapis.com/auth/bigquery * https://www.googleapis.com/auth/bigtable.admin.table
                * https://www.googleapis.com/auth/bigtable.data * https://www.googleapis.com/auth/devstorage.full_control'
              x-dcl-list-type: list
              items:
                type: string
                x-dcl-go-type: string
            subnetwork:
              type: string
              x-dcl-go-name: Subnetwork
              description: 'Optional. The Compute Engine subnetwork to be used for
                machine communications. Cannot be specified with network_uri. A full
                URL, partial URI, or short name are valid. Examples: * `https://www.googleapis.com/compute/v1/projects//regions/us-east1/subnetworks/sub0`
                * `sub0`'
              x-dcl-references:
              - resource: Compute/Subnetwork
                field: selfLink
            tags:
              type: array
              x-dcl-go-name: Tags
              description: The Compute Engine tags to add to all instances (see (https://cloud.google.com/compute/docs/label-or-tag-resources#tags)).
              x-dcl-list-type: set
              items:
                type: string
                x-dcl-go-type: string
            zone:
              type: string
              x-dcl-go-name: Zone
              description: 'Optional. The zone where the Compute Engine cluster will
                be located. On a create request, it is required in the "global" region.
                If omitted in a non-global Dataproc region, the service will pick
                a zone in the corresponding Compute Engine region. On a get request,
                zone will always be present. A full URL, partial URI, or short name
                are valid. Examples: * `https://www.googleapis.com/compute/v1/projects/`
                * `us-central1-f`'
        initializationActions:
          type: array
          x-dcl-go-name: InitializationActions
          description: 'Optional. Commands to execute on each node after config is
            completed. By default, executables are run on master and all worker nodes.
            You can test a node''s `role` metadata to run an executable on a master
            or worker node, as shown below using `curl` (you can also use `wget`):
            ROLE=$(curl -H Metadata-Flavor:Google http://metadata/computeMetadata/v1/instance/attributes/dataproc-role)
            if ; then ... master specific actions ... else ... worker specific actions
            ... fi'
          x-dcl-list-type: list
          items:
            type: object
            x-dcl-go-type: ClusterClusterConfigInitializationActions
            properties:
              executableFile:
                type: string
                x-dcl-go-name: ExecutableFile
                description: Required. Cloud Storage URI of executable file.
              executionTimeout:
                type: string
                x-dcl-go-name: ExecutionTimeout
                description: Optional. Amount of time executable has to complete.
                  Default is 10 minutes (see JSON representation of (https://developers.google.com/protocol-buffers/docs/proto3#json)).
                  Cluster creation fails with an explanatory error message (the name
                  of the executable that caused the error and the exceeded timeout
                  period) if the executable is not completed at end of the timeout
                  period.
        lifecycleConfig:
          type: object
          x-dcl-go-name: LifecycleConfig
          x-dcl-go-type: ClusterClusterConfigLifecycleConfig
          description: Optional. Lifecycle setting for the cluster.
          properties:
            autoDeleteTime:
              type: string
              format: date-time
              x-dcl-go-name: AutoDeleteTime
              description: Optional. The time when cluster will be auto-deleted (see
                JSON representation of (https://developers.google.com/protocol-buffers/docs/proto3#json)).
            autoDeleteTtl:
              type: string
              x-dcl-go-name: AutoDeleteTtl
              description: Optional. The lifetime duration of cluster. The cluster
                will be auto-deleted at the end of this period. Minimum value is 10
                minutes; maximum value is 14 days (see JSON representation of (https://developers.google.com/protocol-buffers/docs/proto3#json)).
            idleDeleteTtl:
              type: string
              x-dcl-go-name: IdleDeleteTtl
              description: Optional. The duration to keep the cluster alive while
                idling (when no jobs are running). Passing this threshold will cause
                the cluster to be deleted. Minimum value is 5 minutes; maximum value
                is 14 days (see JSON representation of (https://developers.google.com/protocol-buffers/docs/proto3#json).
            idleStartTime:
              type: string
              format: date-time
              x-dcl-go-name: IdleStartTime
              readOnly: true
              description: Output only. The time when cluster became idle (most recent
                job finished) and became eligible for deletion due to idleness (see
                JSON representation of (https://developers.google.com/protocol-buffers/docs/proto3#json)).
        masterConfig:
          $ref: '#/components/schemas/InstanceGroupConfig'
          x-dcl-go-name: MasterConfig
        secondaryWorkerConfig:
          $ref: '#/components/schemas/InstanceGroupConfig'
          x-dcl-go-name: SecondaryWorkerConfig
        securityConfig:
          type: object
          x-dcl-go-name: SecurityConfig
          x-dcl-go-type: ClusterClusterConfigSecurityConfig
          description: Optional. Security settings for the cluster.
          properties:
            kerberosConfig:
              type: object
              x-dcl-go-name: KerberosConfig
              x-dcl-go-type: ClusterClusterConfigSecurityConfigKerberosConfig
              description: Kerberos related configuration.
              properties:
                crossRealmTrustAdminServer:
                  type: string
                  x-dcl-go-name: CrossRealmTrustAdminServer
                  description: Optional. The admin server (IP or hostname) for the
                    remote trusted realm in a cross realm trust relationship.
                crossRealmTrustKdc:
                  type: string
                  x-dcl-go-name: CrossRealmTrustKdc
                  description: Optional. The KDC (IP or hostname) for the remote trusted
                    realm in a cross realm trust relationship.
                crossRealmTrustRealm:
                  type: string
                  x-dcl-go-name: CrossRealmTrustRealm
                  description: Optional. The remote realm the Dataproc on-cluster
                    KDC will trust, should the user enable cross realm trust.
                crossRealmTrustSharedPassword:
                  type: string
                  x-dcl-go-name: CrossRealmTrustSharedPassword
                  description: Optional. The Cloud Storage URI of a KMS encrypted
                    file containing the shared password between the on-cluster Kerberos
                    realm and the remote trusted realm, in a cross realm trust relationship.
                enableKerberos:
                  type: boolean
                  x-dcl-go-name: EnableKerberos
                  description: 'Optional. Flag to indicate whether to Kerberize the
                    cluster (default: false). Set this field to true to enable Kerberos
                    on a cluster.'
                kdcDbKey:
                  type: string
                  x-dcl-go-name: KdcDbKey
                  description: Optional. The Cloud Storage URI of a KMS encrypted
                    file containing the master key of the KDC database.
                keyPassword:
                  type: string
                  x-dcl-go-name: KeyPassword
                  description: Optional. The Cloud Storage URI of a KMS encrypted
                    file containing the password to the user provided key. For the
                    self-signed certificate, this password is generated by Dataproc.
                keystore:
                  type: string
                  x-dcl-go-name: Keystore
                  description: Optional. The Cloud Storage URI of the keystore file
                    used for SSL encryption. If not provided, Dataproc will provide
                    a self-signed certificate.
                keystorePassword:
                  type: string
                  x-dcl-go-name: KeystorePassword
                  description: Optional. The Cloud Storage URI of a KMS encrypted
                    file containing the password to the user provided keystore. For
                    the self-signed certificate, this password is generated by Dataproc.
                kmsKey:
                  type: string
                  x-dcl-go-name: KmsKey
                  description: Optional. The uri of the KMS key used to encrypt various
                    sensitive files.
                  x-dcl-references:
                  - resource: Cloudkms/CryptoKey
                    field: selfLink
                realm:
                  type: string
                  x-dcl-go-name: Realm
                  description: Optional. The name of the on-cluster Kerberos realm.
                    If not specified, the uppercased domain of hostnames will be the
                    realm.
                rootPrincipalPassword:
                  type: string
                  x-dcl-go-name: RootPrincipalPassword
                  description: Optional. The Cloud Storage URI of a KMS encrypted
                    file containing the root principal password.
                tgtLifetimeHours:
                  type: integer
                  format: int64
                  x-dcl-go-name: TgtLifetimeHours
                  description: Optional. The lifetime of the ticket granting ticket,
                    in hours. If not specified, or user specifies 0, then default
                    value 10 will be used.
                truststore:
                  type: string
                  x-dcl-go-name: Truststore
                  description: Optional. The Cloud Storage URI of the truststore file
                    used for SSL encryption. If not provided, Dataproc will provide
                    a self-signed certificate.
                truststorePassword:
                  type: string
                  x-dcl-go-name: TruststorePassword
                  description: Optional. The Cloud Storage URI of a KMS encrypted
                    file containing the password to the user provided truststore.
                    For the self-signed certificate, this password is generated by
                    Dataproc.
        softwareConfig:
          type: object
          x-dcl-go-name: SoftwareConfig
          x-dcl-go-type: ClusterClusterConfigSoftwareConfig
          description: Optional. The config settings for software inside the cluster.
          properties:
            imageVersion:
              type: string
              x-dcl-go-name: ImageVersion
              description: Optional. The version of software inside the cluster. It
                must be one of the supported (https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-versions#other_versions).
                If unspecified, it defaults to the latest Debian version.
            optionalComponents:
              type: array
              x-dcl-go-name: OptionalComponents
              description: Optional. The set of components to activate on the cluster.
              x-dcl-list-type: list
              items:
                type: string
                x-dcl-go-type: ClusterClusterConfigSoftwareConfigOptionalComponentsEnum
                enum:
                - COMPONENT_UNSPECIFIED
                - ANACONDA
                - DOCKER
                - DRUID
                - FLINK
                - HBASE
                - HIVE_WEBHCAT
                - JUPYTER
                - KERBEROS
                - PRESTO
                - RANGER
                - SOLR
                - ZEPPELIN
                - ZOOKEEPER
            properties:
              type: object
              additionalProperties:
                type: string
              x-dcl-go-name: Properties
              description: 'Optional. The properties to set on daemon config files.
                Property keys are specified in `prefix:property` format, for example
                `core:hadoop.tmp.dir`. The following are supported prefixes and their
                mappings: * capacity-scheduler: `capacity-scheduler.xml` * core: `core-site.xml`
                * distcp: `distcp-default.xml` * hdfs: `hdfs-site.xml` * hive: `hive-site.xml`
                * mapred: `mapred-site.xml` * pig: `pig.properties` * spark: `spark-defaults.conf`
                * yarn: `yarn-site.xml` For more information, see (https://cloud.google.com/dataproc/docs/concepts/cluster-properties).'
        stagingBucket:
          type: string
          x-dcl-go-name: StagingBucket
          description: Optional. A Cloud Storage bucket used to stage job dependencies,
            config files, and job driver console output. If you do not specify a staging
            bucket, Cloud Dataproc will determine a Cloud Storage location (US, ASIA,
            or EU) for your cluster's staging bucket according to the Compute Engine
            zone where your cluster is deployed, and then create and manage this project-level,
            per-location bucket (see (https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/staging-bucket)).
          x-dcl-references:
          - resource: Storage/Bucket
            field: name
        tempBucket:
          type: string
          x-dcl-go-name: TempBucket
          description: Optional. A Cloud Storage bucket used to store ephemeral cluster
            and jobs data, such as Spark and MapReduce history files. If you do not
            specify a temp bucket, Dataproc will determine a Cloud Storage location
            (US, ASIA, or EU) for your cluster's temp bucket according to the Compute
            Engine zone where your cluster is deployed, and then create and manage
            this project-level, per-location bucket. The default bucket has a TTL
            of 90 days, but you can use any TTL (or none) if you specify a bucket.
          x-dcl-references:
          - resource: Storage/Bucket
            field: name
        workerConfig:
          $ref: '#/components/schemas/InstanceGroupConfig'
          x-dcl-go-name: WorkerConfig
    InstanceGroupConfig:
      type: object
      x-dcl-go-name: WorkerConfig
      x-dcl-go-type: ClusterInstanceGroupConfig
      description: Optional. The Compute Engine config settings for worker instances
        in a cluster.
      x-kubernetes-immutable: true
      x-dcl-server-default: true
      properties:
        accelerators:
          type: array
          x-dcl-go-name: Accelerators
          description: Optional. The Compute Engine accelerator configuration for
            these instances.
          x-kubernetes-immutable: true
          x-dcl-server-default: true
          x-dcl-list-type: list
          items:
            type: object
            x-dcl-go-type: ClusterInstanceGroupConfigAccelerators
            properties:
              acceleratorCount:
                type: integer
                format: int64
                x-dcl-go-name: AcceleratorCount
                description: The number of the accelerator cards of this type exposed
                  to this instance.
                x-kubernetes-immutable: true
              acceleratorType:
                type: string
                x-dcl-go-name: AcceleratorType
                description: Full URL, partial URI, or short name of the accelerator
                  type resource to expose to this instance. See (https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/auto-zone#using_auto_zone_placement)
                  feature, you must use the short name of the accelerator type resource,
                  for example, `nvidia-tesla-k80`.
                x-kubernetes-immutable: true
        diskConfig:
          type: object
          x-dcl-go-name: DiskConfig
          x-dcl-go-type: ClusterInstanceGroupConfigDiskConfig
          description: Optional. Disk option config settings.
          x-kubernetes-immutable: true
          x-dcl-server-default: true
          properties:
            bootDiskSizeGb:
              type: integer
              format: int64
              x-dcl-go-name: BootDiskSizeGb
              description: Optional. Size in GB of the boot disk (default is 500GB).
              x-kubernetes-immutable: true
            bootDiskType:
              type: string
              x-dcl-go-name: BootDiskType
              description: 'Optional. Type of the boot disk (default is "pd-standard").
                Valid values: "pd-ssd" (Persistent Disk Solid State Drive) or "pd-standard"
                (Persistent Disk Hard Disk Drive).'
              x-kubernetes-immutable: true
            numLocalSsds:
              type: integer
              format: int64
              x-dcl-go-name: NumLocalSsds
              description: Optional. Number of attached SSDs, from 0 to 4 (default
                is 0). If SSDs are not attached, the boot disk is used to store runtime
                logs and (https://hadoop.apache.org/docs/r1.2.1/hdfs_user_guide.html)
                data. If one or more SSDs are attached, this runtime bulk data is
                spread across them, and the boot disk contains only basic config and
                installed binaries.
              x-kubernetes-immutable: true
              x-dcl-server-default: true
        image:
          type: string
          x-dcl-go-name: Image
          description: 'Optional. The Compute Engine image resource used for cluster
            instances. The URI can represent an image or image family. Image examples:
            * `https://www.googleapis.com/compute/beta/projects/` If the URI is unspecified,
            it will be inferred from `SoftwareConfig.image_version` or the system
            default.'
          x-kubernetes-immutable: true
          x-dcl-references:
          - resource: Compute/Image
            field: selfLink
        instanceNames:
          type: array
          x-dcl-go-name: InstanceNames
          readOnly: true
          description: Output only. The list of instance names. Dataproc derives the
            names from `cluster_name`, `num_instances`, and the instance group.
          x-kubernetes-immutable: true
          x-dcl-server-default: true
          x-dcl-list-type: list
          items:
            type: string
            x-dcl-go-type: string
            x-dcl-references:
            - resource: Compute/Instance
              field: selfLink
        isPreemptible:
          type: boolean
          x-dcl-go-name: IsPreemptible
          readOnly: true
          description: Output only. Specifies that this instance group contains preemptible
            instances.
          x-kubernetes-immutable: true
        machineType:
          type: string
          x-dcl-go-name: MachineType
          description: 'Optional. The Compute Engine machine type used for cluster
            instances. A full URL, partial URI, or short name are valid. Examples:
            * `https://www.googleapis.com/compute/v1/projects/(https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/auto-zone#using_auto_zone_placement)
            feature, you must use the short name of the machine type resource, for
            example, `n1-standard-2`.'
          x-kubernetes-immutable: true
        managedGroupConfig:
          type: object
          x-dcl-go-name: ManagedGroupConfig
          x-dcl-go-type: ClusterInstanceGroupConfigManagedGroupConfig
          readOnly: true
          description: Output only. The config for Compute Engine Instance Group Manager
            that manages this group. This is only used for preemptible instance groups.
          x-kubernetes-immutable: true
          x-dcl-server-default: true
          properties:
            instanceGroupManagerName:
              type: string
              x-dcl-go-name: InstanceGroupManagerName
              readOnly: true
              description: Output only. The name of the Instance Group Manager for
                this group.
              x-kubernetes-immutable: true
            instanceTemplateName:
              type: string
              x-dcl-go-name: InstanceTemplateName
              readOnly: true
              description: Output only. The name of the Instance Template used for
                the Managed Instance Group.
              x-kubernetes-immutable: true
        minCpuPlatform:
          type: string
          x-dcl-go-name: MinCpuPlatform
          description: Optional. Specifies the minimum cpu platform for the Instance
            Group. See (https://cloud.google.com/dataproc/docs/concepts/compute/dataproc-min-cpu).
          x-kubernetes-immutable: true
          x-dcl-server-default: true
        numInstances:
          type: integer
          format: int64
          x-dcl-go-name: NumInstances
          description: Optional. The number of VM instances in the instance group.
            For master instance groups, must be set to 1.
          x-kubernetes-immutable: true
        preemptibility:
          type: string
          x-dcl-go-name: Preemptibility
          x-dcl-go-type: ClusterInstanceGroupConfigPreemptibilityEnum
          description: 'Optional. Specifies the preemptibility of the instance group.
            The default value for master and worker groups is `NON_PREEMPTIBLE`. This
            default cannot be changed. The default value for secondary instances is
            `PREEMPTIBLE`. Possible values: PREEMPTIBILITY_UNSPECIFIED, NON_PREEMPTIBLE,
            PREEMPTIBLE'
          x-kubernetes-immutable: true
          enum:
          - PREEMPTIBILITY_UNSPECIFIED
          - NON_PREEMPTIBLE
          - PREEMPTIBLE
    WorkflowTemplate:
      title: WorkflowTemplate
      x-dcl-id: projects/{{project}}/locations/{{location}}/workflowTemplates/{{name}}
      x-dcl-parent-container: project
      x-dcl-labels: labels
      type: object
      required:
      - name
      - placement
      - jobs
      - project
      - location
      properties:
        createTime:
          type: string
          format: date-time
          x-dcl-go-name: CreateTime
          readOnly: true
          description: Output only. The time template was created.
          x-kubernetes-immutable: true
        dagTimeout:
          type: string
          x-dcl-go-name: DagTimeout
          description: Optional. Timeout duration for the DAG of jobs. You can use
            "s", "m", "h", and "d" suffixes for second, minute, hour, and day duration
            values, respectively. The timeout duration must be from 10 minutes ("10m")
            to 24 hours ("24h" or "1d"). The timer begins when the first job is submitted.
            If the workflow is running at the end of the timeout period, any remaining
            jobs are cancelled, the workflow is ended, and if the workflow was running
            on a (/dataproc/docs/concepts/workflows/using-workflows#configuring_or_selecting_a_cluster),
            the cluster is deleted.
        jobs:
          type: array
          x-dcl-go-name: Jobs
          description: Required. The Directed Acyclic Graph of Jobs to submit.
          x-dcl-list-type: list
          items:
            type: object
            x-dcl-go-type: WorkflowTemplateJobs
            required:
            - stepId
            properties:
              hadoopJob:
                type: object
                x-dcl-go-name: HadoopJob
                x-dcl-go-type: WorkflowTemplateJobsHadoopJob
                description: Optional. Job is a Hadoop job.
                properties:
                  archiveUris:
                    type: array
                    x-dcl-go-name: ArchiveUris
                    description: 'Optional. HCFS URIs of archives to be extracted
                      in the working directory of Hadoop drivers and tasks. Supported
                      file types: .jar, .tar, .tar.gz, .tgz, or .zip.'
                    x-dcl-list-type: list
                    items:
                      type: string
                      x-dcl-go-type: string
                  args:
                    type: array
                    x-dcl-go-name: Args
                    description: Optional. The arguments to pass to the driver. Do
                      not include arguments, such as `-libjars` or `-Dfoo=bar`, that
                      can be set as job properties, since a collision may occur that
                      causes an incorrect job submission.
                    x-dcl-list-type: list
                    items:
                      type: string
                      x-dcl-go-type: string
                  fileUris:
                    type: array
                    x-dcl-go-name: FileUris
                    description: Optional. HCFS (Hadoop Compatible Filesystem) URIs
                      of files to be copied to the working directory of Hadoop drivers
                      and distributed tasks. Useful for naively parallel tasks.
                    x-dcl-list-type: list
                    items:
                      type: string
                      x-dcl-go-type: string
                  jarFileUris:
                    type: array
                    x-dcl-go-name: JarFileUris
                    description: Optional. Jar file URIs to add to the CLASSPATHs
                      of the Hadoop driver and tasks.
                    x-dcl-list-type: list
                    items:
                      type: string
                      x-dcl-go-type: string
                  loggingConfig:
                    type: object
                    x-dcl-go-name: LoggingConfig
                    x-dcl-go-type: WorkflowTemplateJobsHadoopJobLoggingConfig
                    description: Optional. The runtime log config for job execution.
                    properties:
                      driverLogLevels:
                        type: object
                        additionalProperties:
                          type: string
                        x-dcl-go-name: DriverLogLevels
                        description: 'The per-package log levels for the driver. This
                          may include "root" package name to configure rootLogger.
                          Examples: ''com.google = FATAL'', ''root = INFO'', ''org.apache
                          = DEBUG'''
                  mainClass:
                    type: string
                    x-dcl-go-name: MainClass
                    description: The name of the driver's main class. The jar file
                      containing the class must be in the default CLASSPATH or specified
                      in `jar_file_uris`.
                  mainJarFileUri:
                    type: string
                    x-dcl-go-name: MainJarFileUri
                    description: 'The HCFS URI of the jar file containing the main
                      class. Examples: ''gs://foo-bucket/analytics-binaries/extract-useful-metrics-mr.jar''
                      ''hdfs:/tmp/test-samples/custom-wordcount.jar'' ''file:///home/usr/lib/hadoop-mapreduce/hadoop-mapreduce-examples.jar'''
                  properties:
                    type: object
                    additionalProperties:
                      type: string
                    x-dcl-go-name: Properties
                    description: Optional. A mapping of property names to values,
                      used to configure Hadoop. Properties that conflict with values
                      set by the Dataproc API may be overwritten. Can include properties
                      set in /etc/hadoop/conf/*-site and classes in user code.
              hiveJob:
                type: object
                x-dcl-go-name: HiveJob
                x-dcl-go-type: WorkflowTemplateJobsHiveJob
                description: Optional. Job is a Hive job.
                properties:
                  continueOnFailure:
                    type: boolean
                    x-dcl-go-name: ContinueOnFailure
                    description: Optional. Whether to continue executing queries if
                      a query fails. The default value is `false`. Setting to `true`
                      can be useful when executing independent parallel queries.
                  jarFileUris:
                    type: array
                    x-dcl-go-name: JarFileUris
                    description: Optional. HCFS URIs of jar files to add to the CLASSPATH
                      of the Hive server and Hadoop MapReduce (MR) tasks. Can contain
                      Hive SerDes and UDFs.
                    x-dcl-list-type: list
                    items:
                      type: string
                      x-dcl-go-type: string
                  properties:
                    type: object
                    additionalProperties:
                      type: string
                    x-dcl-go-name: Properties
                    description: Optional. A mapping of property names and values,
                      used to configure Hive. Properties that conflict with values
                      set by the Dataproc API may be overwritten. Can include properties
                      set in /etc/hadoop/conf/*-site.xml, /etc/hive/conf/hive-site.xml,
                      and classes in user code.
                  queryFileUri:
                    type: string
                    x-dcl-go-name: QueryFileUri
                    description: The HCFS URI of the script that contains Hive queries.
                  queryList:
                    type: object
                    x-dcl-go-name: QueryList
                    x-dcl-go-type: WorkflowTemplateJobsHiveJobQueryList
                    description: A list of queries.
                    required:
                    - queries
                    properties:
                      queries:
                        type: array
                        x-dcl-go-name: Queries
                        description: 'Required. The queries to execute. You do not
                          need to end a query expression with a semicolon. Multiple
                          queries can be specified in one string by separating each
                          with a semicolon. Here is an example of a Dataproc API snippet
                          that uses a QueryList to specify a HiveJob: "hiveJob": {
                          "queryList": { "queries": } }'
                        x-dcl-list-type: list
                        items:
                          type: string
                          x-dcl-go-type: string
                  scriptVariables:
                    type: object
                    additionalProperties:
                      type: string
                    x-dcl-go-name: ScriptVariables
                    description: 'Optional. Mapping of query variable names to values
                      (equivalent to the Hive command: `SET name="value";`).'
              labels:
                type: object
                additionalProperties:
                  type: string
                x-dcl-go-name: Labels
                description: 'Optional. The labels to associate with this job. Label
                  keys must be between 1 and 63 characters long, and must conform
                  to the following regular expression: {0,63} No more than 32 labels
                  can be associated with a given job.'
              pigJob:
                type: object
                x-dcl-go-name: PigJob
                x-dcl-go-type: WorkflowTemplateJobsPigJob
                description: Optional. Job is a Pig job.
                properties:
                  continueOnFailure:
                    type: boolean
                    x-dcl-go-name: ContinueOnFailure
                    description: Optional. Whether to continue executing queries if
                      a query fails. The default value is `false`. Setting to `true`
                      can be useful when executing independent parallel queries.
                  jarFileUris:
                    type: array
                    x-dcl-go-name: JarFileUris
                    description: Optional. HCFS URIs of jar files to add to the CLASSPATH
                      of the Pig Client and Hadoop MapReduce (MR) tasks. Can contain
                      Pig UDFs.
                    x-dcl-list-type: list
                    items:
                      type: string
                      x-dcl-go-type: string
                  loggingConfig:
                    type: object
                    x-dcl-go-name: LoggingConfig
                    x-dcl-go-type: WorkflowTemplateJobsPigJobLoggingConfig
                    description: Optional. The runtime log config for job execution.
                    properties:
                      driverLogLevels:
                        type: object
                        additionalProperties:
                          type: string
                        x-dcl-go-name: DriverLogLevels
                        description: 'The per-package log levels for the driver. This
                          may include "root" package name to configure rootLogger.
                          Examples: ''com.google = FATAL'', ''root = INFO'', ''org.apache
                          = DEBUG'''
                  properties:
                    type: object
                    additionalProperties:
                      type: string
                    x-dcl-go-name: Properties
                    description: Optional. A mapping of property names to values,
                      used to configure Pig. Properties that conflict with values
                      set by the Dataproc API may be overwritten. Can include properties
                      set in /etc/hadoop/conf/*-site.xml, /etc/pig/conf/pig.properties,
                      and classes in user code.
                  queryFileUri:
                    type: string
                    x-dcl-go-name: QueryFileUri
                    description: The HCFS URI of the script that contains the Pig
                      queries.
                  queryList:
                    type: object
                    x-dcl-go-name: QueryList
                    x-dcl-go-type: WorkflowTemplateJobsPigJobQueryList
                    description: A list of queries.
                    required:
                    - queries
                    properties:
                      queries:
                        type: array
                        x-dcl-go-name: Queries
                        description: 'Required. The queries to execute. You do not
                          need to end a query expression with a semicolon. Multiple
                          queries can be specified in one string by separating each
                          with a semicolon. Here is an example of a Dataproc API snippet
                          that uses a QueryList to specify a HiveJob: "hiveJob": {
                          "queryList": { "queries": } }'
                        x-dcl-list-type: list
                        items:
                          type: string
                          x-dcl-go-type: string
                  scriptVariables:
                    type: object
                    additionalProperties:
                      type: string
                    x-dcl-go-name: ScriptVariables
                    description: 'Optional. Mapping of query variable names to values
                      (equivalent to the Pig command: `name=`).'
              prerequisiteStepIds:
                type: array
                x-dcl-go-name: PrerequisiteStepIds
                description: Optional. The optional list of prerequisite job step_ids.
                  If not specified, the job will start at the beginning of workflow.
                x-dcl-list-type: list
                items:
                  type: string
                  x-dcl-go-type: string
              prestoJob:
                type: object
                x-dcl-go-name: PrestoJob
                x-dcl-go-type: WorkflowTemplateJobsPrestoJob
                description: Optional. Job is a Presto job.
                properties:
                  clientTags:
                    type: array
                    x-dcl-go-name: ClientTags
                    description: Optional. Presto client tags to attach to this query
                    x-dcl-list-type: list
                    items:
                      type: string
                      x-dcl-go-type: string
                  continueOnFailure:
                    type: boolean
                    x-dcl-go-name: ContinueOnFailure
                    description: Optional. Whether to continue executing queries if
                      a query fails. The default value is `false`. Setting to `true`
                      can be useful when executing independent parallel queries.
                  loggingConfig:
                    type: object
                    x-dcl-go-name: LoggingConfig
                    x-dcl-go-type: WorkflowTemplateJobsPrestoJobLoggingConfig
                    description: Optional. The runtime log config for job execution.
                    properties:
                      driverLogLevels:
                        type: object
                        additionalProperties:
                          type: string
                        x-dcl-go-name: DriverLogLevels
                        description: 'The per-package log levels for the driver. This
                          may include "root" package name to configure rootLogger.
                          Examples: ''com.google = FATAL'', ''root = INFO'', ''org.apache
                          = DEBUG'''
                  outputFormat:
                    type: string
                    x-dcl-go-name: OutputFormat
                    description: Optional. The format in which query output will be
                      displayed. See the Presto documentation for supported output
                      formats
                  properties:
                    type: object
                    additionalProperties:
                      type: string
                    x-dcl-go-name: Properties
                    description: Optional. A mapping of property names to values.
                      Used to set Presto (https://prestodb.io/docs/current/sql/set-session.html)
                      Equivalent to using the --session flag in the Presto CLI
                  queryFileUri:
                    type: string
                    x-dcl-go-name: QueryFileUri
                    description: The HCFS URI of the script that contains SQL queries.
                  queryList:
                    type: object
                    x-dcl-go-name: QueryList
                    x-dcl-go-type: WorkflowTemplateJobsPrestoJobQueryList
                    description: A list of queries.
                    required:
                    - queries
                    properties:
                      queries:
                        type: array
                        x-dcl-go-name: Queries
                        description: 'Required. The queries to execute. You do not
                          need to end a query expression with a semicolon. Multiple
                          queries can be specified in one string by separating each
                          with a semicolon. Here is an example of a Dataproc API snippet
                          that uses a QueryList to specify a HiveJob: "hiveJob": {
                          "queryList": { "queries": } }'
                        x-dcl-list-type: list
                        items:
                          type: string
                          x-dcl-go-type: string
              pysparkJob:
                type: object
                x-dcl-go-name: PysparkJob
                x-dcl-go-type: WorkflowTemplateJobsPysparkJob
                description: Optional. Job is a PySpark job.
                required:
                - mainPythonFileUri
                properties:
                  archiveUris:
                    type: array
                    x-dcl-go-name: ArchiveUris
                    description: 'Optional. HCFS URIs of archives to be extracted
                      into the working directory of each executor. Supported file
                      types: .jar, .tar, .tar.gz, .tgz, and .zip.'
                    x-dcl-list-type: list
                    items:
                      type: string
                      x-dcl-go-type: string
                  args:
                    type: array
                    x-dcl-go-name: Args
                    description: Optional. The arguments to pass to the driver. Do
                      not include arguments, such as `--conf`, that can be set as
                      job properties, since a collision may occur that causes an incorrect
                      job submission.
                    x-dcl-list-type: list
                    items:
                      type: string
                      x-dcl-go-type: string
                  fileUris:
                    type: array
                    x-dcl-go-name: FileUris
                    description: Optional. HCFS URIs of files to be placed in the
                      working directory of each executor. Useful for naively parallel
                      tasks.
                    x-dcl-list-type: list
                    items:
                      type: string
                      x-dcl-go-type: string
                  jarFileUris:
                    type: array
                    x-dcl-go-name: JarFileUris
                    description: Optional. HCFS URIs of jar files to add to the CLASSPATHs
                      of the Python driver and tasks.
                    x-dcl-list-type: list
                    items:
                      type: string
                      x-dcl-go-type: string
                  loggingConfig:
                    type: object
                    x-dcl-go-name: LoggingConfig
                    x-dcl-go-type: WorkflowTemplateJobsPysparkJobLoggingConfig
                    description: Optional. The runtime log config for job execution.
                    properties:
                      driverLogLevels:
                        type: object
                        additionalProperties:
                          type: string
                        x-dcl-go-name: DriverLogLevels
                        description: 'The per-package log levels for the driver. This
                          may include "root" package name to configure rootLogger.
                          Examples: ''com.google = FATAL'', ''root = INFO'', ''org.apache
                          = DEBUG'''
                  mainPythonFileUri:
                    type: string
                    x-dcl-go-name: MainPythonFileUri
                    description: Required. The HCFS URI of the main Python file to
                      use as the driver. Must be a .py file.
                  properties:
                    type: object
                    additionalProperties:
                      type: string
                    x-dcl-go-name: Properties
                    description: Optional. A mapping of property names to values,
                      used to configure PySpark. Properties that conflict with values
                      set by the Dataproc API may be overwritten. Can include properties
                      set in /etc/spark/conf/spark-defaults.conf and classes in user
                      code.
                  pythonFileUris:
                    type: array
                    x-dcl-go-name: PythonFileUris
                    description: 'Optional. HCFS file URIs of Python files to pass
                      to the PySpark framework. Supported file types: .py, .egg, and
                      .zip.'
                    x-dcl-list-type: list
                    items:
                      type: string
                      x-dcl-go-type: string
              scheduling:
                type: object
                x-dcl-go-name: Scheduling
                x-dcl-go-type: WorkflowTemplateJobsScheduling
                description: Optional. Job scheduling configuration.
                properties:
                  maxFailuresPerHour:
                    type: integer
                    format: int64
                    x-dcl-go-name: MaxFailuresPerHour
                    description: Optional. Maximum number of times per hour a driver
                      may be restarted as a result of driver exiting with non-zero
                      code before job is reported failed. A job may be reported as
                      thrashing if driver exits with non-zero code 4 times within
                      10 minute window. Maximum value is 10.
                  maxFailuresTotal:
                    type: integer
                    format: int64
                    x-dcl-go-name: MaxFailuresTotal
                    description: Optional. Maximum number of times in total a driver
                      may be restarted as a result of driver exiting with non-zero
                      code before job is reported failed. Maximum value is 240
              sparkJob:
                type: object
                x-dcl-go-name: SparkJob
                x-dcl-go-type: WorkflowTemplateJobsSparkJob
                description: Optional. Job is a Spark job.
                properties:
                  archiveUris:
                    type: array
                    x-dcl-go-name: ArchiveUris
                    description: 'Optional. HCFS URIs of archives to be extracted
                      into the working directory of each executor. Supported file
                      types: .jar, .tar, .tar.gz, .tgz, and .zip.'
                    x-dcl-list-type: list
                    items:
                      type: string
                      x-dcl-go-type: string
                  args:
                    type: array
                    x-dcl-go-name: Args
                    description: Optional. The arguments to pass to the driver. Do
                      not include arguments, such as `--conf`, that can be set as
                      job properties, since a collision may occur that causes an incorrect
                      job submission.
                    x-dcl-list-type: list
                    items:
                      type: string
                      x-dcl-go-type: string
                  fileUris:
                    type: array
                    x-dcl-go-name: FileUris
                    description: Optional. HCFS URIs of files to be placed in the
                      working directory of each executor. Useful for naively parallel
                      tasks.
                    x-dcl-list-type: list
                    items:
                      type: string
                      x-dcl-go-type: string
                  jarFileUris:
                    type: array
                    x-dcl-go-name: JarFileUris
                    description: Optional. HCFS URIs of jar files to add to the CLASSPATHs
                      of the Spark driver and tasks.
                    x-dcl-list-type: list
                    items:
                      type: string
                      x-dcl-go-type: string
                  loggingConfig:
                    type: object
                    x-dcl-go-name: LoggingConfig
                    x-dcl-go-type: WorkflowTemplateJobsSparkJobLoggingConfig
                    description: Optional. The runtime log config for job execution.
                    properties:
                      driverLogLevels:
                        type: object
                        additionalProperties:
                          type: string
                        x-dcl-go-name: DriverLogLevels
                        description: 'The per-package log levels for the driver. This
                          may include "root" package name to configure rootLogger.
                          Examples: ''com.google = FATAL'', ''root = INFO'', ''org.apache
                          = DEBUG'''
                  mainClass:
                    type: string
                    x-dcl-go-name: MainClass
                    description: The name of the driver's main class. The jar file
                      that contains the class must be in the default CLASSPATH or
                      specified in `jar_file_uris`.
                  mainJarFileUri:
                    type: string
                    x-dcl-go-name: MainJarFileUri
                    description: The HCFS URI of the jar file that contains the main
                      class.
                  properties:
                    type: object
                    additionalProperties:
                      type: string
                    x-dcl-go-name: Properties
                    description: Optional. A mapping of property names to values,
                      used to configure Spark. Properties that conflict with values
                      set by the Dataproc API may be overwritten. Can include properties
                      set in /etc/spark/conf/spark-defaults.conf and classes in user
                      code.
              sparkRJob:
                type: object
                x-dcl-go-name: SparkRJob
                x-dcl-go-type: WorkflowTemplateJobsSparkRJob
                description: Optional. Job is a SparkR job.
                required:
                - mainRFileUri
                properties:
                  archiveUris:
                    type: array
                    x-dcl-go-name: ArchiveUris
                    description: 'Optional. HCFS URIs of archives to be extracted
                      into the working directory of each executor. Supported file
                      types: .jar, .tar, .tar.gz, .tgz, and .zip.'
                    x-dcl-list-type: list
                    items:
                      type: string
                      x-dcl-go-type: string
                  args:
                    type: array
                    x-dcl-go-name: Args
                    description: Optional. The arguments to pass to the driver. Do
                      not include arguments, such as `--conf`, that can be set as
                      job properties, since a collision may occur that causes an incorrect
                      job submission.
                    x-dcl-list-type: list
                    items:
                      type: string
                      x-dcl-go-type: string
                  fileUris:
                    type: array
                    x-dcl-go-name: FileUris
                    description: Optional. HCFS URIs of files to be placed in the
                      working directory of each executor. Useful for naively parallel
                      tasks.
                    x-dcl-list-type: list
                    items:
                      type: string
                      x-dcl-go-type: string
                  loggingConfig:
                    type: object
                    x-dcl-go-name: LoggingConfig
                    x-dcl-go-type: WorkflowTemplateJobsSparkRJobLoggingConfig
                    description: Optional. The runtime log config for job execution.
                    properties:
                      driverLogLevels:
                        type: object
                        additionalProperties:
                          type: string
                        x-dcl-go-name: DriverLogLevels
                        description: 'The per-package log levels for the driver. This
                          may include "root" package name to configure rootLogger.
                          Examples: ''com.google = FATAL'', ''root = INFO'', ''org.apache
                          = DEBUG'''
                  mainRFileUri:
                    type: string
                    x-dcl-go-name: MainRFileUri
                    description: Required. The HCFS URI of the main R file to use
                      as the driver. Must be a .R file.
                  properties:
                    type: object
                    additionalProperties:
                      type: string
                    x-dcl-go-name: Properties
                    description: Optional. A mapping of property names to values,
                      used to configure SparkR. Properties that conflict with values
                      set by the Dataproc API may be overwritten. Can include properties
                      set in /etc/spark/conf/spark-defaults.conf and classes in user
                      code.
              sparkSqlJob:
                type: object
                x-dcl-go-name: SparkSqlJob
                x-dcl-go-type: WorkflowTemplateJobsSparkSqlJob
                description: Optional. Job is a SparkSql job.
                properties:
                  jarFileUris:
                    type: array
                    x-dcl-go-name: JarFileUris
                    description: Optional. HCFS URIs of jar files to be added to the
                      Spark CLASSPATH.
                    x-dcl-list-type: list
                    items:
                      type: string
                      x-dcl-go-type: string
                  loggingConfig:
                    type: object
                    x-dcl-go-name: LoggingConfig
                    x-dcl-go-type: WorkflowTemplateJobsSparkSqlJobLoggingConfig
                    description: Optional. The runtime log config for job execution.
                    properties:
                      driverLogLevels:
                        type: object
                        additionalProperties:
                          type: string
                        x-dcl-go-name: DriverLogLevels
                        description: 'The per-package log levels for the driver. This
                          may include "root" package name to configure rootLogger.
                          Examples: ''com.google = FATAL'', ''root = INFO'', ''org.apache
                          = DEBUG'''
                  properties:
                    type: object
                    additionalProperties:
                      type: string
                    x-dcl-go-name: Properties
                    description: Optional. A mapping of property names to values,
                      used to configure Spark SQL's SparkConf. Properties that conflict
                      with values set by the Dataproc API may be overwritten.
                  queryFileUri:
                    type: string
                    x-dcl-go-name: QueryFileUri
                    description: The HCFS URI of the script that contains SQL queries.
                  queryList:
                    type: object
                    x-dcl-go-name: QueryList
                    x-dcl-go-type: WorkflowTemplateJobsSparkSqlJobQueryList
                    description: A list of queries.
                    required:
                    - queries
                    properties:
                      queries:
                        type: array
                        x-dcl-go-name: Queries
                        description: 'Required. The queries to execute. You do not
                          need to end a query expression with a semicolon. Multiple
                          queries can be specified in one string by separating each
                          with a semicolon. Here is an example of a Dataproc API snippet
                          that uses a QueryList to specify a HiveJob: "hiveJob": {
                          "queryList": { "queries": } }'
                        x-dcl-list-type: list
                        items:
                          type: string
                          x-dcl-go-type: string
                  scriptVariables:
                    type: object
                    additionalProperties:
                      type: string
                    x-dcl-go-name: ScriptVariables
                    description: 'Optional. Mapping of query variable names to values
                      (equivalent to the Spark SQL command: SET `name="value";`).'
              stepId:
                type: string
                x-dcl-go-name: StepId
                description: Required. The step id. The id must be unique among all
                  jobs within the template. The step id is used as prefix for job
                  id, as job `goog-dataproc-workflow-step-id` label, and in field
                  from other steps. The id must contain only letters (a-z, A-Z), numbers
                  (0-9), underscores (_), and hyphens (-). Cannot begin or end with
                  underscore or hyphen. Must consist of between 3 and 50 characters.
        labels:
          type: object
          additionalProperties:
            type: string
          x-dcl-go-name: Labels
          description: Optional. The labels to associate with this template. These
            labels will be propagated to all jobs and clusters created by the workflow
            instance. Label **keys** must contain 1 to 63 characters, and must conform
            to (https://www.ietf.org/rfc/rfc1035.txt). No more than 32 labels can
            be associated with a template.
        location:
          type: string
          x-dcl-go-name: Location
          description: The location for the resource
          x-kubernetes-immutable: true
        name:
          type: string
          x-dcl-go-name: Name
          description: 'Output only. The resource name of the workflow template, as
            described in https://cloud.google.com/apis/design/resource_names. * For
            `projects.regions.workflowTemplates`, the resource name of the template
            has the following format: `projects/{project_id}/regions/{region}/workflowTemplates/{template_id}`
            * For `projects.locations.workflowTemplates`, the resource name of the
            template has the following format: `projects/{project_id}/locations/{location}/workflowTemplates/{template_id}`'
          x-kubernetes-immutable: true
        parameters:
          type: array
          x-dcl-go-name: Parameters
          description: Optional. Template parameters whose values are substituted
            into the template. Values for parameters must be provided when the template
            is instantiated.
          x-dcl-list-type: list
          items:
            type: object
            x-dcl-go-type: WorkflowTemplateParameters
            required:
            - name
            - fields
            properties:
              description:
                type: string
                x-dcl-go-name: Description
                description: Optional. Brief description of the parameter. Must not
                  exceed 1024 characters.
              fields:
                type: array
                x-dcl-go-name: Fields
                description: Required. Paths to all fields that the parameter replaces.
                  A field is allowed to appear in at most one parameter's list of
                  field paths. A field path is similar in syntax to a .sparkJob.args
                x-dcl-list-type: list
                items:
                  type: string
                  x-dcl-go-type: string
              name:
                type: string
                x-dcl-go-name: Name
                description: Required. Parameter name. The parameter name is used
                  as the key, and paired with the parameter value, which are passed
                  to the template when the template is instantiated. The name must
                  contain only capital letters (A-Z), numbers (0-9), and underscores
                  (_), and must not start with a number. The maximum length is 40
                  characters.
              validation:
                type: object
                x-dcl-go-name: Validation
                x-dcl-go-type: WorkflowTemplateParametersValidation
                description: Optional. Validation rules to be applied to this parameter's
                  value.
                properties:
                  regex:
                    type: object
                    x-dcl-go-name: Regex
                    x-dcl-go-type: WorkflowTemplateParametersValidationRegex
                    description: Validation based on regular expressions.
                    required:
                    - regexes
                    properties:
                      regexes:
                        type: array
                        x-dcl-go-name: Regexes
                        description: Required. RE2 regular expressions used to validate
                          the parameter's value. The value must match the regex in
                          its entirety (substring matches are not sufficient).
                        x-dcl-list-type: list
                        items:
                          type: string
                          x-dcl-go-type: string
                  values:
                    type: object
                    x-dcl-go-name: Values
                    x-dcl-go-type: WorkflowTemplateParametersValidationValues
                    description: Validation based on a list of allowed values.
                    required:
                    - values
                    properties:
                      values:
                        type: array
                        x-dcl-go-name: Values
                        description: Required. List of allowed values for the parameter.
                        x-dcl-list-type: list
                        items:
                          type: string
                          x-dcl-go-type: string
        placement:
          type: object
          x-dcl-go-name: Placement
          x-dcl-go-type: WorkflowTemplatePlacement
          description: Required. WorkflowTemplate scheduling information.
          properties:
            clusterSelector:
              type: object
              x-dcl-go-name: ClusterSelector
              x-dcl-go-type: WorkflowTemplatePlacementClusterSelector
              description: Optional. A selector that chooses target cluster for jobs
                based on metadata. The selector is evaluated at the time each job
                is submitted.
              required:
              - clusterLabels
              properties:
                clusterLabels:
                  type: object
                  additionalProperties:
                    type: string
                  x-dcl-go-name: ClusterLabels
                  description: Required. The cluster labels. Cluster must have all
                    labels to match.
                zone:
                  type: string
                  x-dcl-go-name: Zone
                  description: Optional. The zone where workflow process executes.
                    This parameter does not affect the selection of the cluster. If
                    unspecified, the zone of the first cluster matching the selector
                    is used.
            managedCluster:
              type: object
              x-dcl-go-name: ManagedCluster
              x-dcl-go-type: WorkflowTemplatePlacementManagedCluster
              description: A cluster that is managed by the workflow.
              required:
              - clusterName
              - config
              properties:
                clusterName:
                  type: string
                  x-dcl-go-name: ClusterName
                  description: Required. The cluster name prefix. A unique cluster
                    name will be formed by appending a random suffix. The name must
                    contain only lower-case letters (a-z), numbers (0-9), and hyphens
                    (-). Must begin with a letter. Cannot begin or end with hyphen.
                    Must consist of between 2 and 35 characters.
                config:
                  $ref: '#/components/schemas/ClusterConfig'
                  x-dcl-go-name: Config
                labels:
                  type: object
                  additionalProperties:
                    type: string
                  x-dcl-go-name: Labels
                  description: 'Optional. The labels to associate with this cluster.
                    Label keys must be between 1 and 63 characters long, and must
                    conform to the following PCRE regular expression: {0,63} No more
                    than 32 labels can be associated with a given cluster.'
        project:
          type: string
          x-dcl-go-name: Project
          description: The project for the resource
          x-kubernetes-immutable: true
          x-dcl-references:
          - resource: Cloudresourcemanager/Project
            field: name
            parent: true
        updateTime:
          type: string
          format: date-time
          x-dcl-go-name: UpdateTime
          readOnly: true
          description: Output only. The time template was last updated.
          x-kubernetes-immutable: true
        version:
          type: integer
          format: int64
          x-dcl-go-name: Version
          description: Optional. Used to perform a consistent read-modify-write. This
            field should be left blank for a `CreateWorkflowTemplate` request. It
            is required for an `UpdateWorkflowTemplate` request, and must match the
            current server version. A typical update template flow would fetch the
            current template with a `GetWorkflowTemplate` request, which will return
            the current template with the `version` field filled in with the current
            server version. The user updates other fields in the template, then returns
            it as part of the `UpdateWorkflowTemplate` request.
          x-dcl-server-default: true
